{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchvision in /home/msurapathi1/.local/lib/python3.8/site-packages (0.15.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib64/python3.8/site-packages (from torchvision) (8.1.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/site-packages (from torchvision) (2.25.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib64/python3.8/site-packages (from torchvision) (1.22.3)\n",
      "Requirement already satisfied: torch==2.0.0 in /home/msurapathi1/.local/lib/python3.8/site-packages (from torchvision) (2.0.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/msurapathi1/.local/lib/python3.8/site-packages (from torch==2.0.0->torchvision) (11.7.99)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/msurapathi1/.local/lib/python3.8/site-packages (from torch==2.0.0->torchvision) (10.2.10.91)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/site-packages (from torch==2.0.0->torchvision) (4.1.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/msurapathi1/.local/lib/python3.8/site-packages (from torch==2.0.0->torchvision) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/msurapathi1/.local/lib/python3.8/site-packages (from torch==2.0.0->torchvision) (11.7.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/msurapathi1/.local/lib/python3.8/site-packages (from torch==2.0.0->torchvision) (2.14.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/site-packages (from torch==2.0.0->torchvision) (3.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/msurapathi1/.local/lib/python3.8/site-packages (from torch==2.0.0->torchvision) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/msurapathi1/.local/lib/python3.8/site-packages (from torch==2.0.0->torchvision) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/msurapathi1/.local/lib/python3.8/site-packages (from torch==2.0.0->torchvision) (11.10.3.66)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.8/site-packages (from torch==2.0.0->torchvision) (2.6.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/msurapathi1/.local/lib/python3.8/site-packages (from torch==2.0.0->torchvision) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/msurapathi1/.local/lib/python3.8/site-packages (from torch==2.0.0->torchvision) (10.9.0.58)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/msurapathi1/.local/lib/python3.8/site-packages (from torch==2.0.0->torchvision) (2.0.0)\n",
      "Requirement already satisfied: sympy in /home/msurapathi1/.local/lib/python3.8/site-packages (from torch==2.0.0->torchvision) (1.11.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/site-packages (from torch==2.0.0->torchvision) (2.11.2)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/msurapathi1/.local/lib/python3.8/site-packages (from torch==2.0.0->torchvision) (11.4.0.1)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchvision) (0.37.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchvision) (51.1.2)\n",
      "Requirement already satisfied: cmake in /home/msurapathi1/.local/lib/python3.8/site-packages (from triton==2.0.0->torch==2.0.0->torchvision) (3.26.3)\n",
      "Requirement already satisfied: lit in /home/msurapathi1/.local/lib/python3.8/site-packages (from triton==2.0.0->torch==2.0.0->torchvision) (16.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests->torchvision) (1.26.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests->torchvision) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/site-packages (from requests->torchvision) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests->torchvision) (2020.12.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib64/python3.8/site-packages (from jinja2->torch==2.0.0->torchvision) (1.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/msurapathi1/.local/lib/python3.8/site-packages (from sympy->torch==2.0.0->torchvision) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.8 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from PIL import Image\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset class\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, compressed_dir, high_quality_dir, transform=None):\n",
    "        self.compressed_dir = compressed_dir\n",
    "        self.high_quality_dir = high_quality_dir\n",
    "        self.transform = transform\n",
    "        self.compressed_files = os.listdir(self.compressed_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.compressed_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        compressed_file = self.compressed_files[index]\n",
    "        compressed_path = os.path.join(self.compressed_dir, compressed_file)\n",
    "        split_file = re.split(r'\\.|_', compressed_file)\n",
    "        high_quality_file = split_file[0] + '.png'\n",
    "        high_quality_path = os.path.join(self.high_quality_dir, high_quality_file)\n",
    "\n",
    "        compressed_image = Image.open(compressed_path)\n",
    "        high_quality_image = Image.open(high_quality_path)\n",
    "\n",
    "        if self.transform:\n",
    "            compressed_image = self.transform(compressed_image)\n",
    "            high_quality_image = self.transform(high_quality_image)\n",
    "\n",
    "        return compressed_image, high_quality_image\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x/255.0)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageEnhancer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageEnhancer, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=(1,1))\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=(1,1))\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=(1,1))\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=(1,1))\n",
    "        self.relu4 = nn.ReLU(inplace=True)\n",
    "        self.conv5 = nn.Conv2d(128, 3, kernel_size=3, padding=(1,1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.conv5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1       [-1, 64, 1024, 1024]           1,792\n",
      "              ReLU-2       [-1, 64, 1024, 1024]               0\n",
      "            Conv2d-3       [-1, 64, 1024, 1024]          36,928\n",
      "              ReLU-4       [-1, 64, 1024, 1024]               0\n",
      "            Conv2d-5      [-1, 128, 1024, 1024]          73,856\n",
      "              ReLU-6      [-1, 128, 1024, 1024]               0\n",
      "            Conv2d-7      [-1, 128, 1024, 1024]         147,584\n",
      "              ReLU-8      [-1, 128, 1024, 1024]               0\n",
      "            Conv2d-9        [-1, 3, 1024, 1024]           3,459\n",
      "================================================================\n",
      "Total params: 263,619\n",
      "Trainable params: 263,619\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 12.00\n",
      "Forward/backward pass size (MB): 6168.00\n",
      "Params size (MB): 1.01\n",
      "Estimated Total Size (MB): 6181.01\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = ImageEnhancer()\n",
    "from torchsummary import summary\n",
    "summary(model, (3, 1024, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for compressed_images, high_quality_images in dataloader:\n",
    "        compressed_images = compressed_images.to(device)\n",
    "        high_quality_images = high_quality_images.to(device)\n",
    "        print('Data loaded..', end='')\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(compressed_images)\n",
    "        print('Optimizer done..', end='')\n",
    "        loss = criterion(outputs, high_quality_images)\n",
    "        loss.backward()\n",
    "        print('Backprop done..', end='')\n",
    "        optimizer.step()\n",
    "        print('Weights updated.')\n",
    "        running_loss += loss.item() * compressed_images.size(0)\n",
    "\n",
    "    return running_loss / len(dataloader.dataset)\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for compressed_images, high_quality_images in dataloader:\n",
    "            compressed_images = compressed_images.to(device)\n",
    "            high_quality_images = high_quality_images.to(device)\n",
    "\n",
    "            outputs = model(compressed_images)\n",
    "            loss = criterion(outputs, high_quality_images)\n",
    "\n",
    "            running_loss += loss.item() * compressed_images.size(0)\n",
    "\n",
    "    return running_loss / len(dataloader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_dir = 'compressed_images'\n",
    "high_quality_dir = 'images'\n",
    "\n",
    "val_high_quality_dir = 'val_images'\n",
    "val_compressed_dir = 'compressed_val_images'\n",
    "\n",
    "# Define data transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x/255.0)\n",
    "])\n",
    "\n",
    "\n",
    "# Create dataset and dataloader\n",
    "train_dataset = ImageDataset(compressed_dir, high_quality_dir, transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=20, shuffle=True, num_workers=0)\n",
    "\n",
    "val_dataset = ImageDataset(val_compressed_dir, val_high_quality_dir, transform)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=True, num_workers=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in the model: 263619\n"
     ]
    }
   ],
   "source": [
    "model = ImageEnhancer()\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of parameters in the model: {num_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = ImageEnhancer()\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting epoch:  0\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done..Backprop done..Weights updated.\n",
      "Data loaded..Optimizer done.."
     ]
    }
   ],
   "source": [
    "\n",
    "i = 1024\n",
    "while True:\n",
    "    try:\n",
    "        # Define data transformation\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((i, i)),  \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: x/255.0)\n",
    "        ])\n",
    "\n",
    "        # Create dataset and dataloader\n",
    "        train_dataset = ImageDataset(compressed_dir, high_quality_dir, transform)\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=20, shuffle=True, num_workers=0)\n",
    "\n",
    "        val_dataset = ImageDataset(val_compressed_dir, val_high_quality_dir, transform)\n",
    "        val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=True, num_workers=0)\n",
    "\n",
    "\n",
    "        import time\n",
    "        from tqdm import tqdm\n",
    "\n",
    "        column_names = ['train_loss', 'val_loss']\n",
    "        losses = pd.DataFrame(columns=column_names)\n",
    "        num_epochs = 30\n",
    "        best_val_loss = float('inf')\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print('starting epoch: ', epoch)\n",
    "            start_time = time.time()\n",
    "            # Train the model\n",
    "            train_loss = train(model, train_dataloader, criterion, optimizer, device)\n",
    "\n",
    "            # Evaluate the model on the validation set\n",
    "            with torch.no_grad():\n",
    "                val_loss = evaluate(model, val_dataloader, criterion, device)\n",
    "\n",
    "            losses.loc[epoch, 'train_loss'] = train_loss\n",
    "            losses.loc[epoch, 'val_loss'] = val_loss\n",
    "            losses.to_csv('cnn_big_samepad_prog.csv')\n",
    "\n",
    "            end_time = time.time()\n",
    "            epoch_mins, epoch_secs = divmod(end_time - start_time, 60)\n",
    "            eta_mins, eta_secs = divmod((end_time - start_time) * (num_epochs - epoch - 1), 60)\n",
    "\n",
    "            # Save the model if validation loss improves\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                torch.save(model.state_dict(), 'image_enhancer_cnn_big_1pad.pth')\n",
    "\n",
    "            print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
    "                  f\"Epoch Time: {epoch_mins:.0f}m {epoch_secs:.0f}s, ETA: {eta_mins:.0f}m {eta_secs:.0f}s\")\n",
    "\n",
    "        # Save the final trained model\n",
    "        torch.save(model.state_dict(), 'final_image_enhancer_cnn_big_samepad.pth')\n",
    "        break\n",
    "        \n",
    "    except RuntimeError as e:\n",
    "        print('Trying ', i)\n",
    "        i -= 100\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = ImageEnhancer()\n",
    "model.load_state_dict(torch.load('image_enhancer_ep.pth'))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Load a compressed image to enhance\n",
    "compressed_image_path = os.path.join('compressed_images', '00076_compressed.jpg')\n",
    "compressed_image = Image.open('test.jpg')\n",
    "compressed_image = transform(compressed_image).unsqueeze(0).to(device)\n",
    "\n",
    "# Enhance the compressed image\n",
    "with torch.no_grad():\n",
    "    enhanced_image = model(compressed_image)\n",
    "enhanced_image = enhanced_image.squeeze(0).cpu().numpy().transpose(1, 2, 0)\n",
    "enhanced_image = Image.fromarray((enhanced_image * 255).astype('uint8'))\n",
    "\n",
    "# Save the enhanced image\n",
    "enhanced_image.save('enhanced_image_test.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
